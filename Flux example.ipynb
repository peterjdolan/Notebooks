{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mPrecompiling module Flux.\n",
      "\u001b[39mWARNING: using Iterators.groupby in module Flux conflicts with an existing identifier.\n",
      "WARNING: using Iterators.imap in module Flux conflicts with an existing identifier.\n",
      "2017-06-22 10:28:43.724213: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-06-22 10:28:43.724261: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mMethodError: no method matching TensorFlow.Tensor(::Flux.Chain, ::TensorFlow.Tensor{Float32})\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mMethodError: no method matching TensorFlow.Tensor(::Flux.Chain, ::TensorFlow.Tensor{Float32})\u001b[39m",
      ""
     ]
    }
   ],
   "source": [
    "using Flux, Juno\n",
    "\n",
    "conv1 = Chain(\n",
    "  Conv2D((5,5), out = 20), tanh,\n",
    "  MaxPool((2,2), stride = (2,2)))\n",
    "\n",
    "conv2 = Chain(\n",
    "  Conv2D((5,5), in = 20, out = 50), tanh,\n",
    "  MaxPool((2,2), stride = (2,2)))\n",
    "\n",
    "lenet = @Chain(\n",
    "  Input(28,28,1),\n",
    "  conv1, conv2,\n",
    "  flatten,\n",
    "  Affine(500), tanh,\n",
    "  Affine(10), softmax)\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "# Now we can continue exactly as in plain TensorFlow, following\n",
    "#   https://github.com/malmaud/TensorFlow.jl/blob/master/examples/mnist_full.jl\n",
    "# (taking only the training and cost logic, not the graph building steps)\n",
    "\n",
    "using TensorFlow, Distributions\n",
    "\n",
    "include(Pkg.dir(\"TensorFlow\", \"examples\", \"mnist_loader.jl\"))\n",
    "loader = DataLoader()\n",
    "\n",
    "session = Session(Graph())\n",
    "\n",
    "x  = placeholder(Float32)\n",
    "y′ = placeholder(Float32)\n",
    "y  = Tensor(lenet, x)\n",
    "\n",
    "cross_entropy = reduce_mean(-reduce_sum(y′.*log(y), reduction_indices=[2]))\n",
    "\n",
    "train_step = train.minimize(train.AdamOptimizer(1e-4), cross_entropy)\n",
    "\n",
    "accuracy = reduce_mean(cast(indmax(y, 2) .== indmax(y′, 2), Float32))\n",
    "\n",
    "run(session, global_variables_initializer())\n",
    "\n",
    "@progress for i in 1:1000\n",
    "    batch = next_batch(loader, 50)\n",
    "    if i%100 == 1\n",
    "        train_accuracy = run(session, accuracy, Dict(x=>batch[1], y′=>batch[2]))\n",
    "        info(\"step $i, training accuracy $train_accuracy\")\n",
    "    end\n",
    "    run(session, train_step, Dict(x=>batch[1], y′=>batch[2]))\n",
    "end\n",
    "\n",
    "testx, testy = load_test_set()\n",
    "test_accuracy = run(session, accuracy, Dict(x=>testx, y′=>testy))\n",
    "info(\"test accuracy $test_accuracy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.0",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
